# -*- coding: utf-8 -*-
"""EXERCISE4-Object Detection and Recognition-CAYADONG-4B.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HyKUzn9YMmB2Pkw2rFvt_wj8CGC8E2w_

# **CSST 106** - Perception and Computer Vision

**Name:** Cayadong, Marjelaine M.

**Program, Year & Section:** BSCS - 4B

**Install Necessary Libraries**
"""

!pip install ultralytics
!pip install tensorflow opencv-python matplotlib
!pip install -U tensorflow==2.13 tensorflow_hub opencv-python-headless
!pip install tf_slim

"""**Import Necessary Libraries**"""

import time
import cv2
from skimage.feature import hog
import matplotlib.pyplot as plt
import numpy as np
from ultralytics import YOLO
from google.colab.patches import cv2_imshow
import tensorflow as tf
import tensorflow_hub as hub

"""***Task 1 : HOG (Histogram of Oriented Gradients) Object Detection***"""

# Load an image
image = cv2.imread('catto.jpg')

gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply HOG descriptor
features, hog_image = hog(
        gray_image,
        orientations=9,
        pixels_per_cell=(8, 8),
        cells_per_block=(2, 2),
        visualize=True
    )

    # Normalize the HOG image to improve brightness
hog_image = (hog_image - hog_image.min()) / (hog_image.max() - hog_image.min())

    # Display the HOG image
plt.figure(figsize=(12, 6))
plt.axis('off')
plt.imshow(hog_image, cmap='gray')
plt.show()

"""***Task 2: YOLO (You Only Look Once) Object Detection***"""

# Load YOLO model and Configuration
net = YOLO('yolov8n.pt', 'yolov3.weights', 'yolov3.cfg')

# Load an image
image = cv2.imread('catto.jpg')

# To check if the image was loaded successfully
if image is None:
    raise FileNotFoundError("Image not found. Please check the image path.")

# Perform inference
results = net(image)

for result in results:
    boxes = result.boxes
    for box in boxes:
        x1, y1, x2, y2 = box.xyxy[0].numpy()  # Get the bounding box coordinates
        conf = box.conf[0].item()
        class_id = int(box.cls[0].item())  # Get the class ID

        if conf > 0.5:
            label = f"Class: {class_id}, Confidence: {conf:.2f}"
            # Check bounding box and label
            cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
            cv2.putText(image, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

# Display the image
plt.figure(figsize=(12, 6))
plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.title('YOLO Detection')
plt.show()

"""***Task 3: SSD (Single Shot MultiBox Detector) with TensorFlow***"""

# Load the pre-trained SSD MobileNet model from TensorFlow Hub
model_url = "https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2"
detector = hub.load(model_url)

# Load the uploaded image
image_path = '/content/catto.jpg'  # Path to the uploaded image
image_np = cv2.imread(image_path)
image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for correct display in matplotlib

# Prepare the image as input tensor
input_tensor = tf.convert_to_tensor(image_np)
input_tensor = input_tensor[tf.newaxis, ...]  # Add batch dimension

# Run the SSD model on the image
detections = detector(input_tensor)

# Visualize bounding boxes on the image
# Process detections
num_detections = int(detections.pop("num_detections"))
detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}
detections["num_detections"] = num_detections
detection_scores = detections['detection_scores']
detection_boxes = detections['detection_boxes']
detection_classes = detections['detection_classes'].astype(np.int64)

# Draw bounding boxes on the image
for i in range(num_detections):
    if detection_scores[i] > 0.5:  # Display only confident detections
        ymin, xmin, ymax, xmax = detection_boxes[i]
        left, right, top, bottom = (xmin * image_np.shape[1], xmax * image_np.shape[1],
                                    ymin * image_np.shape[0], ymax * image_np.shape[0])

        # Draw bounding box
        cv2.rectangle(image_np, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)

# Step 8: Display the image with bounding boxes
plt.figure(figsize=(12, 6))
plt.imshow(image_np)
plt.title('SSD Detection')
plt.axis('off')
plt.show()

"""***Task 4: Traditional vs. Deep Learning Object Detection Comparison***"""

def display_image(image, title):
    plt.figure(figsize=(12, 6))
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for proper color display
    plt.axis('off')
    plt.title(title)
    plt.show()

# Load the pre-trained YOLO model
model = YOLO('yolov8n.pt')  # Use a pre-trained YOLOv8 model

# Load an image for detection
image_path = 'cutie.jpg'
image_yolo = cv2.imread(image_path)

# Check if the image was loaded successfully
if image_yolo is None:
    raise FileNotFoundError("Image not found. Please check the image path.")

# --------- YOLO Detection ---------
start_time_yolo = time.time()  # Start time for YOLO speed measurement
results = model(image_yolo)  # Perform inference
end_time_yolo = time.time()  # End time for YOLO speed measurement

# Process YOLO results
for result in results:
    boxes = result.boxes  # Get the boxes from the detection results
    for box in boxes:
        x1, y1, x2, y2 = box.xyxy[0].numpy()  # Get the bounding box coordinates
        conf = box.conf[0].item()  # Get the confidence score
        class_id = int(box.cls[0].item())  # Get the class ID

        if conf > 0.5:  # Filter out low confidence detections
            label = f"Class: {class_id}, Confidence: {conf:.2f}"
            # Draw bounding box and label
            cv2.rectangle(image_yolo, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
            cv2.putText(image_yolo, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

# Display YOLO detection results
display_image(image_yolo, 'YOLO Detection')
print(f"YOLO Processing Time: {end_time_yolo - start_time_yolo:.4f} seconds")


# --------- HOG-SVM Detection ---------
hog = cv2.HOGDescriptor()
hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())

# Load the same image for HOG-SVM detection
image_hog = cv2.imread(image_path)

# Check if the image was loaded successfully
if image_hog is None:
    raise FileNotFoundError("Image not found. Please check the image path.")

# Perform HOG detection
start_time_hog = time.time()  # Start time for HOG speed measurement
boxes, weights = hog.detectMultiScale(image_hog, winStride=(8, 8), padding=(8, 8), scale=1.05)
end_time_hog = time.time()  # End time for HOG speed measurement

# Draw bounding boxes on the HOG-SVM image
for (x, y, w, h) in boxes:
    cv2.rectangle(image_hog, (x, y), (x + w, y + h), (0, 255, 0), 2)

# Display HOG-SVM detection results
display_image(image_hog, 'HOG-SVM Detection')
print(f"HOG-SVM Processing Time: {end_time_hog - start_time_hog:.4f} seconds")