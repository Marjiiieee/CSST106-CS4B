# -*- coding: utf-8 -*-
"""4B-CAYADONG-MP5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YVEmaccIk3yaxstFr7ggzwboFPNOKKX5

# **CSST 106** - Perception and Computer Vision

**Name:** Cayadong, Marjelaine M.

**Program, Year & Section:** BSCS - 4B

**Install Necessary Libraries**
"""

!pip install ultralytics

"""**Import Necessary Libraries**"""

import cv2
import time
import matplotlib.pyplot as plt
from ultralytics import YOLO

"""**Model Loading**: Use TensorFlow to load a pre-trained YOLO model."""

# Load the pre-trained YOLO model
model = YOLO('yolov8n.pt')  # Use a pre-trained YOLOv8 model

"""**Image Input**: Select an image that contains multiple objects"""

# List of image paths to test and their corresponding labels
image_paths = ['cats1.jpg', 'cats2.jpg', 'cats3.jpg']
labels = ['Cats 1', 'Cats 2', 'Cats 3']

"""**Object Detection**: Feed the selected image to the YOLO model to detect various objects within it."""

# Function to perform object detection, measure performance, and display images
def analyze_performance(image_path, label):
    image = cv2.imread(image_path)

    # Check if the image was loaded successfully
    if image is None:
        raise FileNotFoundError(f"Image not found: {image_path}")

    # Measuring time generating
    start_time = time.time()
    results = model(image)
    end_time = time.time()

    # Calculate the time taken for inference
    inference_time = end_time - start_time
    print(f"Inference Time for {image_path}: {inference_time:.4f} seconds")
    detected_objects = 0
    for result in results:
        boxes = result.boxes
        detected_objects += len(boxes)

        # Iterate through each detected box
        for box in boxes:
            x1, y1, x2, y2 = box.xyxy[0].numpy()
            conf = box.conf[0].item()
            class_id = int(box.cls[0].item())

            if conf > 0.5:
                cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
                cv2.putText(image, f"Class: {class_id}, Conf: {conf:.2f}",
                            (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Output the number detected
    print(f"Number of Detected Objects in {image_path}: {detected_objects}")

    # Adding a labels
    cv2.putText(image, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)

    # Display the image with detections using matplotlib
    plt.figure(figsize=(10, 10))  # Set figure size for the plot
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct color display
    plt.axis('off')  # Hide the axis
    plt.title(f'{label} Detection Results')  # Set the title of the plot
    plt.show()  # Show the plot

"""**Visualization**: Display the detected objects using bounding boxes and class labels."""

# Analyze performance for each image with corresponding labels
for img_path, label in zip(image_paths, labels):
    analyze_performance(img_path, label)